### FSD技术补充
#### FSD版本信息
上次报告中的芯片信息为V12版本信息，但部分技术在V11中有所应用，如occupancy Network。其中被宣传最广的端对端应用，在FSD V11 beta版上也已有应用。目前主要资料来源为：Tesla AI day 2022以及CVPR 2023 Conferance.

信息链接如下：

[Tesla AI Day](https://www.youtube.com/watch?v=ODSJsviD_SU&t=5s)

[CVPR Conference 2023 Autonomy Driving](https://www.youtube.com/watch?v=6x-Xb_uT7ts&t=20s)

[CVPR Conference 2023 E2EAD](https://www.youtube.com/watch?v=OKDRsVXv49A&t=1462s)

#### FSD特点
目前FSD技术主要的特点为：
- 端对端网络结构，由规则驱动改向数据驱动；
- 不需要人工标注；（这一点与上次报告中不同，会在下面进行阐述）
- 通过强大算力建立起world model，可以表征大量信息；
- 后续架构可能由transformer转向diffusion；（Musk 推特信息）

#### Occupancy Network
> 输入：8个车载摄像头的视频输入（36帧/秒）；
> 
> 输出：周围环境空间网格占有情况以及运动流信息，以向量空间信息表示;

与传统自动驾驶场景处理方式不同，FSD对周围空间进行划分，对于每个网格中的占有情况进行分析预测。占有情况指，该网格是否存在对车子行驶有威胁的元素存在。

这样对于车辆来说，其不需要知道所看到的物体是什么，只需要知道前方是否存在障碍即可。

网络架构如下：
![](ON.jpg)

工作流程如下：
- 视频矫正（畸变矫正）
- 利用网络提取图片信息，网络结构不固定，可以使用各种特征提取网络；
- 提取信息作为key/value，同时构建3D query；
- 利用以上的query,key,value进行spatial attention,抓取空间中的特定信息；
- 不同时刻得到的attention结果进行联合，使其能够体现出运动特征；
- 联合结果经过deconvolution得到输出；

输出结果展示了每个网格的占有情况以及其可能的运动情况。

#### World Model
通过上面的网络，FSD发现了在大批视频数据的训练下神经网络展现出的强大能力，认为，在大量数据训练下，整个网络可以作为一个世界基础，对周围环境中的任何元素进行识别、模拟，甚至对整个环境进行重建，并能够预测在当前状态下，未来一段时间内车辆周围行驶环境变动；

其原理示意如下：
![](wm.jpg)

![](wm2.jpg)

其中，特斯拉着重展示的两个应用案例为：
- 道路路标识别以及道路网络生成；
![](lane.jpg)
- 道路红绿灯自主识别并识别路灯关联车道；
![](trf.jpg)

其中，目前用到的网络架构还是transformer（根据2022 Tesla AI day上信息得到）。

整个world model更像是一个世界模拟器，可以对当前场景的未来做出不同的预测，并采取相应动作。

根据CVPR2023上的报告，可以大致了解整个的FSD训练过程：
![Alt text](image.png)

首先，部署基本模型到车辆上，主要作用就是收集数据。数据主要包括两方面：摄像头拍摄的行驶数据以及驾驶员的操控数据。

训练时，模型会利用摄像头的行驶数据预测未来场景，并做出决策，同时这个决策会与驾驶员的决策进行对比。错误决策数据以及极端数据会被传回特斯拉计算平台进行训练，期间会进行标注，标注细节并未提及，目前猜测为，行驶视频上标注驾驶员的操作行为。但整个的标注是通过自回归模型进行自我标注的，并没有用到人工进行标注。

这里需要强调的是，在后期训练过程中，特斯拉提到利用的是一个自主标注流网络进行标注（auto-label pipeline）,人工标注主要是基础模型上使用的。

但整个的标注过程，会有工程师进行关注。进行标注完的数据会被作为良好的训练数据喂给部署在车辆上的模型，从而让模型能够更好的工作。

#### FSD与GPT
FSD更像是自动驾驶界的GPT，但其处理的不是文本序列或者二维图像信息，而是高维空间信息。其都利用向量空间来存储数据中所包含的大量特征，并通过有效的网络架构对这些特征进行处理。

目前FSD尝试利用diffusion作为核心网络架构，有学者认为，是因为diffusion相对于transformer更利于在tesla的NPU上进行并行计算。同时diffusion对图像及视频信息的处理和生成能力更加强大，这也可能是其采用diffusion的原因之一。


### 什么是端对端模型
端到端模型（end-to-end model）是一种深度学习的方法，它可以直接从原始数据（如图像、语音、文本等）到最终的结果（如分类、检测、翻译等）进行训练和预测，而不需要人工设计和提取特征。端到端模型的优点是可以利用神经网络的强大能力来自动学习数据的内在结构和规律，从而提高模型的性能和泛化能力。端到端模型的缺点是需要大量的数据和计算资源，以及合适的网络结构和损失函数。

### 数据驱动和规则驱动
FSD的V11版本之前都是采用的传统的分模块设计，包括感知、决策、控制等多个模块，各任务内部采用各自的算法模型。其中AI算法主要应用在感知模块，决策、控制模块还是基于if else逻辑的代码。

例如，之前的工作流程是：

图片输入 --> 图像中的目标识别 --> 图像分割 --> 基于规则生成决策 -->输出控制信号

现在的工作流程：
图片输入 --> FSD ON网络进行重建 --> 训练mlp模型生成输出信号
